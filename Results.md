
# The result of the experiments

## K-Fold only use train sets and validation sets
 The MUTAG dataset was used with 10-fold cross-validation. Using the method in sklearn, random_state is fixed to 1. The highest validation accuracy is extracted from each fold as the accuracy of that fold, and finally the model's accuracy is calculated by averaging.
## Update 2023/9/13
1. Do all the experiments on MUTAG, and create tables.  :fast_forward:
2. Using faster kernel. :fast_forward: 
3. Early stop
4. Trying different attentions.
5. Positional encoding
6. Multi head attention


## Grid Search Area 
batch-size: 32

num-layers: 1-3

num-hop: 1-3 (IMDB-B is 1-2)

num-wl iteration: 3-5 (IMDB-B is 1-3)

## Grid Search Result with 200 Patience with best val loss(new folds)
Our_new experiments used fixed 32 batch, same as GraphiT
| Method/Dataset | MUTAG | PTC | PROTEINS | NCI1 |AIDS|IMDB-B|
| :-----:| :------: | :------: | :----: | :---:| :---:|:---:|
| Ours |82.95+/-2.6| 54.40+/-2.7|73.67+/-1.3|71.12+/-0.7 ||
| Ours + k=3 |82.92+/-2.5|54.98+/-2.0 |74.22+/-1.2|71.39+/-0.7 | |
| Ours + k=4 |81.87+/-2.3|54.97+/-1.8 |73.58+/-1.3|71.39+/-0.9 | |
| Ours + k=5 |85.58+/-2.6|52.96+/-3.2|73.77+/-1.6|71.75+/-0.7 | |
| Ours_new |85.09+/-2.6|57.57+/-2.4|75.11+/-1.2|71.70+/-0.5|99.45+/-0.1|73.30+/-1.4|
| GCN|75.99+/-3.5| 56.11+/-2.8 |71.60+/-0.8 |74.53+/-0.7 |94.55+/-0.4 |72.80+/-1.8|
| DGCNN |85.03+/-2.7 |50.60+/-2.2 |73.86+/-0.7 |74.38+/-0.7 |99.40+/-0.1|71.90+/-1.4|
| DiffPool |81.35+/-2.5 |57.83+/-2.3 |71.25+/-1.5 |79.32+/-0.9 |99.15+/-0.1 |70.50+/-1.2|
| ECC |80.82+/-4.2 |50.87+/-2.8 |71.17+/-1.0 |75.82+/-0.5 |96.05+/-0.2|70.40+/-1.8|
| GIN |80.26+/-3.1 |58.69+/-1.6 |74.76+/-0.9 |78.89+/-0.6 |99.35+/-0.2|72.30+/-1.2|
| GraphSAGE |72.22+/-2.8 |55.78+/-2.7|71.25+/-1.5 |77.44+/-0.7 |97.40+/-0.3|71.30+/-2.3|
| Transformer |72.78+/-3.6 |51.74+/-2.0 |70.98+/-1.1 |65.67+/-0.7 |94.70+/-0.5|72.40+/-1.5|
| GraphiT + diffusion|81.46+/-2.6 |60.14+/-2.1 |74.21+/-1.2 |76.69+/-0.7 |96.75+/-0.5|70.60+/-1.5|
| GraphiT + adj |79.27+/-1.7 |57.84+/-2.5 |71.07+/-1.4 |77.96+/-0.7 |95.85+/-0.4|71.90+/-1.4|
| GraphiT + GCKN|81.93+/-2.2|59.91+/-3.2|70.98+/-1.3|78.91+/-0.7|98.40+/-2.5|71.10+/-1.5|
|SAT|79.68+/-3.4||||||

## Average total time cost
Total time (without pos and kernel)

The results of Our's MUTAG are a bit different than before because I re-ran the code to be able to calculate total time and withou kernel time at once.
| Method/Dataset | MUTAG | PTC | PROTEINS | NCI1 |AIDS|IMDB-B|
| :-----:| :------: | :------: | :----: | :---:| :---: |:---:|
| Ours |72.13+/-23.55<br>(66.89+/-23.54)|71.49+/-6.74<br>(62.62+/-6.71) |288.06+/-39.86<br>(217.98+/-40.16)| | |
| Ours + k=3 || || | |
| Ours + k=4 || || | |
| Ours + k=5 |||| | |
| Ours_new |(22.23+/-4.08)|(27.27+/-6.04)|(165.39+/-15.08)|(339.04+/-21.18) |(178.25+/-11.26)|(86.92+/-1.1)|
| GCN|35.46+/-8.62|25.88+/-4.13 |193.24+/-37.00 |340.24+/-38.75 | 
| DGCNN |40.33+/-5.7 |26.31+/-5.5 |87.97+/-10.06 |330.68+/-15.77 |
| DiffPool |17.52+/-2.9 |28.92+/-2.76|122.05+/-17.80 |324.19+/-42.07| 
| ECC |39.49+/-5.79 |57.13+/-3.54 |291.51+/-38.24 |1357.29+/-162.07 |
| GIN |12.72+/-1.57 |18.33+/-2.22 |67.39+/-8.02 |282.93+/-19.74 ||
| GraphSAGE |14.86+/-2.31 |18.15+/-1.56|113.37+/-14.78 |331.66+/-40.91 |
| Transformer |12.89+/-0.65 |26.37+/-1.90|133.21+/-25.68 |306.66+/-34.51||
| GraphiT + diffusion|17.53+/-1.38<br>(16.65+/-1.38)|32.36+/-2.73<br>(30.85+/-2.73)|203.73+/-14.46<br>(194.63+/-14.47) |485.92+/-16.39<br>(460.45+/-16.38) |(192.51+/-10.80)|(82.60+/-5.93)|
| GraphiT + adj |25.00+/-4.54<br>(24.95+/-4.54) |28.81+/-2.40<br>(28.72+/-2.40) |182.79+/-11.27<br>(182.40+/-11.27) |421.41+/-6.27<br>(420.38+/-6.30) |(205.27+/-9.13)|(90.12+/-4.16)|
| GraphiT + GCKN|28.99+/-4.37<br>(28.78+/-4.37)|30.37+/-1.97<br>(29.95+/-1.97)|88.88+/-6.93<br>(77.97+/-5.37)|235.25+/-17.93<br>(226.03+/-17.61)|(163.24+/-42.34)|(75.91+/-4.2)|
|SAT|||||||

## Average epoch time

For 32 batch size 3 layers 1 head attention
| Method/Dataset | MUTAG | PTC | PROTEINS | NCI1 |AIDS|IMDB-BINARY|
| :-----:| :------: | :------: | :----: | :---:|:---:|:---:|
| Ours_new |0.0302+/-0.0028|0.0500+/-0.0003|0.1713+/-0.0020|0.6015+/-0.0025|0.2820+/-0.0013|0.1494+/-0.0006|
| Transformer|0.0447+/-0.0028|0.1079+/-0.0025|0.3530+/-0.0029|1.0032+/-0.0032|0.6065+/-0.0050|0.3189+/-0.0042|
| GraphiT + diffusion|0.0674+/-0.0028|0.1126+/-0.0023|0.4306+/-0.0022|1.3182+/-0.0032|0.7695+/-0.0022|0.3968+/-0.0023|
| GraphiT + adj |0.0730+/-0.0018|0.1161+/-0.0023|0.4452+/-0.0023|1.1167+/-0.0031|0.7672+/-0.0024|0.4039+/-0.0025|
|GraphiT + GCKN|0.0631+/-0.0017|0.1067+/-0.0018|0.3503+/-0.0019|1.2486+/-0.0025|0.5856+/-0.0018|0.3248+/-0.0019|
|SAT + 1 layer GCN|0.5384+/-0.0034|1.0112+/-0.0039|3.2894+/-0.0045|11.9323+/-0.0088|5.7834+/-0.0038|2.9415+/-0.0039|

## Parameter Counting
For 3 layers 1 head attention
| Method/Dataset | MUTAG | PTC | PROTEINS | NCI1 |AIDS|IMDB-BINARY|
| :-----:| :------: | :------: | :----: | :---:|:---:|:---:|
| Ours_new |79810|80514 |79554|81730 |81794 |88066|
| GraphiT + diffusion|104386|105090|104130|106306|106370|112642|
| GraphiT + adj |104386|105090|104130|106306|106370|112642|
|GraphiT + GCKN|111362|112066|111106|113282|113346|119618|
|SAT + 1 layer GCN|142594|143298|142338|144514|144578| 150850|

## Ablation Study
We check the MUTAG and PROTEINS dataset with different hops and WL iteration
| Hop/Iteration |1 | 2 | 3 | 4 | 5 |
| :-----:| :------: | :------: | :----: | :---: | :---: |
| 1 |79.62+/-3.93|83.00+/-2.71|86.67+/-2.52|84.53+/-3.22 |85.06+/-2.70|
| 2 |78.07+/-3.55|80.79+/-2.76|80.29+/-3.60|82.98+/-3.39|84.47+/-3.09|
| 3 |78.60+/-3.53|81.81+/-2.80|79.71+/-3.45|80.26+/-2.74|82.34+/-2.58|


| Hop/Iteration | 1| 2|  3 | 4 | 5 |
| :-----:| :------: | :------: | :----: |:----:|:----:|
| 1 |74.22+/-1.14|74.13+/-1.66|74.48+/-1.37|74.12+/-1.48 |74.30+/-1.22|
| 2 |75.29+/-1.25|75.57+/-1.33|73.41+/-1.15|73.77+/-1.19|72.60+/-1.23|
| 3 |75.38+/-1.20|74.31+/-1.30|74.22+/-1.19|72.87+/-1.26|72.58+/-1.47|

## Heatmap
### MUTAG
![Graph1_1hop_WL3](Figures/MUTAG/Graph1_WL3.png)![Graph1_2hop_WL3](Figures/MUTAG/Graph1_2hopWL3.png)![Graph1_3hop_WL3](Figures/MUTAG/Graph1_3hopWL3.png)![Graph1_4hop_WL3](Figures/MUTAG/Graph1_4hopWL3.png)![Graph1_5hop_WL3](Figures/MUTAG/Graph1_5hopWL3.png)




## WL_GPU document
The WL_GPU framework is divided into WL_Conv and WL. WL_Conv handles specific WL convolutions, while WL manages the entire multi-layered WL hashing process. When compared with the CPU-based method (GraKeL), enhancements in the GPU method improve computational efficiency. Datasets are batch-processed and integrated into the dataloader during training. In each WL iteration, Unique labels or colors within subgraphs are enumerated, and color histograms are extracted. Using torch_scatter, node labels aggregate neighboring labels. Nodes then receive a new "hash code" â€” a numerical representation of inherent and neighboring features, contrasting the string-based hashing in CPU methods. After multiple iterations, node labels produce subgraph-wide histograms, representing the subgraph's structure. By comparing these histograms, structural similarity between nodes is assessed. Despite the CPU's parallel capabilities, the GPU method offers superior memory and computational performance.
